import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import roc_auc_score, RocCurveDisplay, mean_squared_error, r2_score, confusion_matrix
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from xgboost import XGBClassifier, XGBRegressor
from sklearn.impute import SimpleImputer

# ------------------ Configura√ß√£o visual ------------------
st.set_page_config(page_title="An√°lise Autom√°tica", layout="wide")

# Tema customizado via CSS
st.markdown(
    """
    <style>
    body {
        background-color: #F5F5F5;
        color: #333333;
    }
    h1, h2, h3 {
        color: #1E88E5;
    }
    .stTabs [data-baseweb="tab"] {
        background-color: #E3F2FD;
        color: #1E88E5;
        font-weight: bold;
    }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("üîç An√°lise Autom√°tica ‚Äî Classifica√ß√£o ou Regress√£o")

# ------------------ Carregamento de dados ------------------
uploaded = st.file_uploader("Selecione o arquivo CSV", type=['csv'])
if uploaded is not None:
    df = pd.read_csv(uploaded)
    st.success("‚úÖ Arquivo carregado com sucesso")
else:
    st.stop()

# ------------------ Sele√ß√£o da vari√°vel alvo ------------------
alvo = st.selectbox("Selecione a vari√°vel alvo", df.columns)
X = df.drop(columns=[alvo])
y = df[alvo]

# ------------------ Pr√©-processamento ------------------
num_cols = X.select_dtypes(include=['float64','int64']).columns.tolist()
cat_cols = [c for c in X.columns if c not in num_cols]

numeric_tf = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])
categorical_tf = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OneHotEncoder(handle_unknown='ignore'))])

preprocess = ColumnTransformer([('num', numeric_tf, num_cols), ('cat', categorical_tf, cat_cols)])

# ------------------ Detectar tipo de problema ------------------
is_classification = (y.dtype == 'object') or (len(y.unique()) < 20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ------------------ Layout com abas ------------------
tab1, tab2, tab3, tab4 = st.tabs(["üìÇ Dados", "‚öôÔ∏è Modelos", "üìä Gr√°ficos", "üìë Relat√≥rio"])

relatorio = ""

with tab1:
    st.subheader("üìÇ Dados Carregados")
    st.write(df.head())
    st.write("Formato:", df.shape)

with tab2:
    st.subheader("‚öôÔ∏è Treinamento e Compara√ß√£o de Modelos")
    if is_classification:
        modelos = {
            "Regress√£o Log√≠stica": LogisticRegression(max_iter=300),
            "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
            "XGBoost": XGBClassifier(n_estimators=200, random_state=42, eval_metric='logloss')
        }
        resultados = {}
        for nome, modelo in modelos.items():
            pipe = Pipeline([('prep', preprocess), ('model', modelo)])
            pipe.fit(X_train, y_train)
            y_proba = pipe.predict_proba(X_test)[:,1]
            auc = roc_auc_score(y_test, y_proba)
            resultados[nome] = auc
        st.write("M√©tricas ROC-AUC:", resultados)
        melhor_modelo = max(resultados, key=resultados.get)
        relatorio = f"""
# üìë Relat√≥rio de Interpreta√ß√£o ‚Äî Classifica√ß√£o

## üìä Desempenho dos Modelos
| Modelo               | ROC-AUC |
|----------------------|---------|
| Regress√£o Log√≠stica  | {resultados['Regress√£o Log√≠stica']:.3f} |
| Random Forest        | {resultados['Random Forest']:.3f} |
| XGBoost              | {resultados['XGBoost']:.3f} |

**‚û° Melhor modelo:** `{melhor_modelo}`

---

## üéØ Conclus√£o
O modelo **{melhor_modelo}** apresentou o melhor desempenho e √© indicado para prever a vari√°vel alvo.
"""
    else:
        modelos = {
            "Regress√£o Linear": LinearRegression(),
            "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
            "XGBoost": XGBRegressor(n_estimators=200, random_state=42)
        }
        resultados = {}
        for nome, modelo in modelos.items():
            pipe = Pipeline([('prep', preprocess), ('model', modelo)])
            pipe.fit(X_train, y_train)
            y_pred = pipe.predict(X_test)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)
            resultados[nome] = {"RMSE": rmse, "R¬≤": r2}
        st.write("M√©tricas:", resultados)
        melhor_modelo = min(resultados, key=lambda k: resultados[k]["RMSE"])
        relatorio = f"""
# üìë Relat√≥rio de Interpreta√ß√£o ‚Äî Regress√£o

## üìä Desempenho dos Modelos
| Modelo              | RMSE   | R¬≤    |
|---------------------|--------|-------|
| Regress√£o Linear    | {resultados['Regress√£o Linear']['RMSE']:.3f} | {resultados['Regress√£o Linear']['R¬≤']:.3f} |
| Random Forest       | {resultados['Random Forest']['RMSE']:.3f} | {resultados['Random Forest']['R¬≤']:.3f} |
| XGBoost             | {resultados['XGBoost']['RMSE']:.3f} | {resultados['XGBoost']['R¬≤']:.3f} |

**‚û° Melhor modelo:** `{melhor_modelo}`

---

## üéØ Conclus√£o
O modelo **{melhor_modelo}** apresentou o melhor desempenho e √© indicado para prever a vari√°vel alvo.
"""

with tab3:
    st.subheader("üìä Gr√°ficos de Diagn√≥stico")
    if is_classification:
        # Curvas ROC
        fig, ax = plt.subplots()
        for nome, modelo in modelos.items():
            pipe = Pipeline([('prep', preprocess), ('model', modelo)])
            pipe.fit(X_train, y_train)
            y_proba = pipe.predict_proba(X_test)[:,1]
            RocCurveDisplay.from_predictions(y_test, y_proba, name=nome, ax=ax)
        st.pyplot(fig)

        # Matriz de confus√£o (Random Forest)
        melhor_rf = Pipeline([('prep', preprocess), ('model', modelos["Random Forest"])])
        melhor_rf.fit(X_train, y_train)
        y_pred_rf = melhor_rf.predict(X_test)
        cm = confusion_matrix(y_test, y_pred_rf)
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
        ax.set_xlabel("Previsto")
        ax.set_ylabel("Real")
        st.pyplot(fig)

    else:
        # Gr√°fico de res√≠duos (corrigido com pipeline)
        fig, ax = plt.subplots()
        pipe = Pipeline([('prep', preprocess), ('model', list(modelos.values())[0])])
        pipe.fit(X_train, y_train)
        y_pred = pipe.predict(X_test)
        ax.scatter(y_pred, y_test - y_pred)
        ax.axhline(0, color='red')
        ax.set_title("Res√≠duos vs Valores preditos")
        st.pyplot(fig)

        # Import√¢ncia das vari√°veis (Random Forest)
        rf_model = Pipeline([('prep', preprocess), ('model', modelos["Random Forest"])])
        rf_model.fit(X_train, y_train)
        nomes_features = num_cols.copy()
        if len(cat_cols) > 0:
            encoder = rf_model.named_steps['prep'].named_transformers_['cat'].named_steps['encoder']
            nomes_features.extend(encoder.get_feature_names_out(cat_cols))
        importancias = rf_model.named_steps['model'].feature_importances_
        indices = np.argsort(importancias)[::-1][:15]
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.barh([nomes_features[i] for i in indices][::-1], importancias[indices][::-1], color="#1E88E5")
        ax.set_xlabel("Import√¢ncia")
        ax.set_title("Top 15 Vari√°veis mais Relevantes")
        st.pyplot(fig)

with tab4:
    st.subheader("üìë Relat√≥rio Interpretativo")

    # Renderiza√ß√£o em Markdown (bonito e formatado)
    st.markdown(relatorio)

    # Caixa de texto com o relat√≥rio bruto (para copiar/editar)
    st.text_area("Relat√≥rio em texto bruto:", relatorio, height=300